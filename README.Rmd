CodeBook.md
# Course Project, Getting and Cleaning Data
***
## Project Description
This project prepares a tidy data set, from a specific set of input data that contains smartphone accelerometer data from 30 individuals.  

**author**: Neil Strange  
**date**: 21.Sep.2015  

**input**: A subdirectory of source data: "UCI HAR Dataset" should be in the current working directory, containing accelerometer data from a number of subjects. A zip of this data is available from https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip.  

**output**: One tidy data file is produced - for each subject and activity combination a list of the mean of each measurement.  

## Dependencies
This script loads and uses the following additional packages:  
* dplyr, 0.4.3 or later
* data.table, 1.9.4 or later 
* reshape2, 1.4.1 or later  

## Interpretation of 'Tidy Data' for this Project
Data is considered tidy if it

*Columns are named and the names are meaningful*: the data is scientific, the measurement names provided in the features file are appropriate for scientific use and are more meaningful than the original column names V1, V2... V561.  
*Coded Values are Substituted for codes*: where activity codes 1..6 were used these are replaced with the corresponding strings set out in the activity_labels file, where 1 = WALKING, 2 = WALKING_UPSTAIRS, etc.  
*One measure per row*: the original data contains multiple measure columns (561 columns of measures, reduced to 85 of interest), these can be reduced to two columns: variable and value, note that - in order not to lose the fact that a number of measures were made at the same time, an extra column is added 'observation number' before melting the data set to retain the linkage between different observed measures.

## Data Processing
### Raw Source Data
Source data is contained in a directory structure which should be in the script's working directory when launched. This directory should have the name: "UCI HAR Dataset".  

The structure includes a number of subdirectories and files:  
* *\test* - a directory containing the test data set (see below)
* *\train* - a directory containing the training data set (see below)
* *activity_labels.txt* - a list of labels used to describe activities, activity data is stored in the test/training data sets using an integer number (1-6), this file contains the corresponding lookup values, i.e. a value of 1 is a 'WALKING' activity. The assignment asks these labels to be substituted for the integers in the target tidy data set.
* *features.txt* - a list of 561 measurements made by the sensor
* *features_info.txt* - a description of how the measurements were made and how they are structured
* *README.txt* - a description of the experimental source of the data, how measurements were made, the directories and files that comprise the data set and information about licensing  
Measurements were made for a number of subjects. The measures were divided into two sets - a test data set and a training data set, each set has its own subdirectory - \test and \train, and they contain further subdirectories and files. The \test and \train directories have identical structures, the table below describes the \test directory contents, however it is applicable to \train as well, just substitute file names using '_test' with '_train':  
* X_test - contains measurements, one row per measurement event, each row with 561 observations labelled V1, V2, ...V561
* y_test - contains information about activities performed, as integers 1-6 (see features.txt to decode these), there is one entry in y_test for each entry in X_test and these correspond - so the first entry in y_test is the activity underway for the first measurement set in X_test
* subject_test - contains information about the subject being measured, identified as an integer, there is one entry in subject_test for each entry in X_test and these correspond - so the first entry in subject_test is the subject of the first measurement set in X_test
* \Inertial Signals - low-level body accelerator and body gyro data over a number of files, this is too low a level for use in this project and can be ignored  

### Target Data

### Processing Steps
The script contains a number of steps:  
step 1 - initial preparation
This step verifies the working directory contains the data set and saves environment variables so they can be reset on exit.

step 2 - read in the X_% data files
Keep the files separate until they are ready to be merged.

step 3 - rename the data file columns
Use a more user-friendly set of names taken from the features.txt file

step 4 - append the y_% activity data
Create a new column in X_% and column bind the y_% activity data. Replace activity codes with the activity labels to make them readable.

step 5 - append the subject_% data
Create a new column in X_% and column bind the subject_% data.

step 6 - merge the test and training data sets
Merge the data sets into X_data holding the combined set.

step 7 drop any non-mean or non-standard deviation measures
Build a logical vector that indicates if a feature includes the text fragments 'mean' or 'std' use the logical vector to drop any columns we don't need, note that columns 1-2 contain subject and activity data and are also retained. This reduces the 561 measurement columns down to 87.

step 8 - melt the data set, reduce 87 measurement columns to a variable and value column.
Each row contains 87 measures plus a subject and activity column. One row is in place for each measurement. To retain the linkage between a measurement and the 87 measures prepend an index to the data set before melting, this index identifies the particular measurement, ensuring it isn't lost, and allows original data to be reconstructed.

step 9 - calculate means for each measure by subject and activity

step 10 - print the tidy data set 
Print the results to a file "tidy_data.txt" with row.name = FALSE

step 11 - restore the environment
Reset the environment to where it was when the script started.


## Description of Variables

tBodyAcc-mean-X
tBodyAcc-mean-Y
tBodyAcc-mean-Z
tBodyAcc-std-X
tBodyAcc-std-Y
tBodyAcc-std-Z

tGravityAcc-mean-X
tGravityAcc-mean-Y
tGravityAcc-mean-Z
tGravityAcc-std-X
tGravityAcc-std-Y
tGravityAcc-std-Z

tBodyAccJerk-mean-X
tBodyAccJerk-mean-Y
tBodyAccJerk-mean-Z
tBodyAccJerk-std-X
tBodyAccJerk-std-Y
tBodyAccJerk-std-Z

tBodyGyro-mean-X
tBodyGyro-mean-Y
tBodyGyro-mean-Z
tBodyGyro-std-X
tBodyGyro-std-Y
tBodyGyro-std-Z

tBodyGyroJerk-mean-X
tBodyGyroJerk-mean-Y
tBodyGyroJerk-mean-Z
tBodyGyroJerk-std-X
tBodyGyroJerk-std-Y
tBodyGyroJerk-std-Z

tBodyAccMag-mean
tBodyAccMag-std
tGravityAccMag-mean
tGravityAccMag-std

tBodyAccJerkMag-mean
tBodyAccJerkMag-std

tBodyGyroMag-mean
tBodyGyroMag-std

tBodyGyroJerkMag-mean
tBodyGyroJerkMag-std

fBodyAcc-mean-X
fBodyAcc-mean-Y
fBodyAcc-mean-Z
fBodyAcc-std-X
fBodyAcc-std-Y
fBodyAcc-std-Z

fBodyAcc-meanFreq-X
fBodyAcc-meanFreq-Y
fBodyAcc-meanFreq-Z

fBodyAccJerk-mean-X
fBodyAccJerk-mean-Y
fBodyAccJerk-mean-Z

fBodyAccJerk-std-X
fBodyAccJerk-std-Y
fBodyAccJerk-std-Z
fBodyAccJerk-meanFreq-X
fBodyAccJerk-meanFreq-Y
fBodyAccJerk-meanFreq-Z

fBodyGyro-mean-X
fBodyGyro-mean-Y
fBodyGyro-mean-Z
fBodyGyro-std-X
fBodyGyro-std-Y
fBodyGyro-std-Z
fBodyGyro-meanFreq-X
fBodyGyro-meanFreq-Y
fBodyGyro-meanFreq-Z
fBodyAccMag-mean
fBodyAccMag-std
fBodyAccMag-meanFreq
fBodyBodyAccJerkMag-mean
fBodyBodyAccJerkMag-std
fBodyBodyAccJerkMag-meanFreq
fBodyBodyGyroMag-mean
fBodyBodyGyroMag-std
fBodyBodyGyroMag-meanFreq
fBodyBodyGyroJerkMag-mean
fBodyBodyGyroJerkMag-std
fBodyBodyGyroJerkMag-meanFreq
angletBodyAccJerkMean,gravityMean
angletBodyGyroMean,gravityMean
angletBodyGyroJerkMean,gravityMean
angleX,gravityMean
angleY,gravityMean
angleZ,gravityMean

## Sources





